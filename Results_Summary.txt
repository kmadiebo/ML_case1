The classification report for logistic regression approach is : 
              precision    recall  f1-score   support

           0       0.87      0.96      0.91       487
           1       0.63      0.32      0.42       101

    accuracy                           0.85       588
   macro avg       0.75      0.64      0.67       588
weighted avg       0.83      0.85      0.83       588

The classification report for SVM approach is : 
              precision    recall  f1-score   support

           0       0.86      0.96      0.91       487
           1       0.56      0.27      0.36       101

    accuracy                           0.84       588
   macro avg       0.71      0.61      0.63       588
weighted avg       0.81      0.84      0.81       588

The classification report for Kernel-SVM (or SVC) approach is : 
              precision    recall  f1-score   support

           0       0.84      0.99      0.91       487
           1       0.70      0.07      0.13       101

    accuracy                           0.84       588
   macro avg       0.77      0.53      0.52       588
weighted avg       0.81      0.84      0.77       588

The classification report for KNN approach is : 
              precision    recall  f1-score   support

           0       0.85      0.97      0.91       487
           1       0.56      0.18      0.27       101

    accuracy                           0.84       588
   macro avg       0.71      0.57      0.59       588
weighted avg       0.80      0.84      0.80       588

The classification report for Naive Bayes approach is : 
              precision    recall  f1-score   support

           0       0.88      0.80      0.84       487
           1       0.33      0.47      0.39       101

    accuracy                           0.75       588
   macro avg       0.60      0.64      0.61       588
weighted avg       0.78      0.75      0.76       588

The classification report for Decision Tree approach is : 
              precision    recall  f1-score   support

           0       0.85      0.85      0.85       487
           1       0.27      0.27      0.27       101

    accuracy                           0.75       588
   macro avg       0.56      0.56      0.56       588
weighted avg       0.75      0.75      0.75       588

The classification report for Random Forest approach is : 
              precision    recall  f1-score   support

           0       0.84      0.99      0.91       487
           1       0.67      0.10      0.17       101

    accuracy                           0.84       588
   macro avg       0.75      0.54      0.54       588
weighted avg       0.81      0.84      0.78       588

The classification report for Cat-G Boost approach is : 
              precision    recall  f1-score   support

           0       0.84      0.99      0.91       487
           1       0.73      0.11      0.19       101

    accuracy                           0.84       588
   macro avg       0.79      0.55      0.55       588
weighted avg       0.82      0.84      0.79       588

The classification report for Stacking Base Models (Logistic, SVM, SVC, Cat-G Boost) approach is : 
              precision    recall  f1-score   support

           0       0.85      0.92      0.88       501
           1       0.18      0.10      0.13        87

    accuracy                           0.80       588
   macro avg       0.52      0.51      0.51       588
weighted avg       0.75      0.80      0.77       588

The classification report for Deep Learning Model approach is : 
              precision    recall  f1-score   support

           0       0.88      0.94      0.91       487
           1       0.54      0.37      0.44       101

    accuracy                           0.84       588
   macro avg       0.71      0.65      0.67       588
weighted avg       0.82      0.84      0.83       588


Optimal number of features: 46
